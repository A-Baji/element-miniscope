{"config": {"indexing": "full", "lang": ["en"], "min_search_length": 3, "prebuild_index": false, "separator": "[\\s\\-]+"}, "docs": [{"location": "", "text": "Element Miniscope Calcium Imaging \u00b6 This Element features a DataJoint schema for functional calcium imaging data acquired with the UCLA Miniscope and Miniscope DAQ V4 acquisition system, and analyzed with CaImAn . For details about the tables in the miniscope schema, see the concepts page Citation \u00b6 If your work DataJoint Elements, please cite the following manuscript and Research Resource Identifier (RRID). Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D, Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358 DataJoint Elements ( RRID:SCR_021894 ) - Element Miniscope (version <Enter version number> )", "title": "Element Miniscope"}, {"location": "#element-miniscope-calcium-imaging", "text": "This Element features a DataJoint schema for functional calcium imaging data acquired with the UCLA Miniscope and Miniscope DAQ V4 acquisition system, and analyzed with CaImAn . For details about the tables in the miniscope schema, see the concepts page", "title": "Element Miniscope Calcium Imaging"}, {"location": "#citation", "text": "If your work DataJoint Elements, please cite the following manuscript and Research Resource Identifier (RRID). Yatsenko D, Nguyen T, Shen S, Gunalan K, Turner CA, Guzman R, Sasaki M, Sitonic D, Reimer J, Walker EY, Tolias AS. DataJoint Elements: Data Workflows for Neurophysiology. bioRxiv. 2021 Jan 1. doi: https://doi.org/10.1101/2021.03.30.437358 DataJoint Elements ( RRID:SCR_021894 ) - Element Miniscope (version <Enter version number> )", "title": "Citation"}, {"location": "concepts/", "text": "Concepts \u00b6 Miniscopes in Neuroscience Research \u00b6 Miniature fluorescence microscopes (miniscopes) are a head-mounted calcium imaging full-frame video modality first introduced in 2005 by Mark Schnitzer's lab ( Flusberg et al., Optics Letters 2005 ). Due to their light weight, these miniscopes allow measuring the dynamic activity of populations of cortical neurons in freely behaving animals. In 2011, Inscopix Inc. was founded to support one-photon miniscopes as a commercial neuroscience research platform, providing proprietary hardware, acquisition software, and analysis software. Today, they estimate their active user base is 491 labs with a total of 1179 installs. An open-source alternative was launched by a UCLA team led by Daniel Aharoni and Peyman Golshani ( Cai et al., Nature 2016 ; Aharoni and Hoogland, Frontiers in Cellular Neuroscience 2019 ). In our conversation with Dr. Aharoni, he estimated about 700 labs currently using the UCLA system alone. The Inscopix user base is smaller but more established. Several two-photon miniscopes have been developed but lack widespread adoption likely due to the expensive hardware required for the two-photon excitation ( Helmchen et al., Neuron 2001 ; Zong et al., Nature Methods 2017 ; Aharoni and Hoogland, Frontiers in Cellular Neuroscience 2019 ). Due to the low costs and ability to record during natural behaviors, one-photon miniscope imaging appears to be the fastest growing calcium imaging modality in the field today. In Year 1, we focused our efforts on supporting the UCLA platform due its fast growth and deficiency of standardization in acquisition and processing pipelines. In future phases, we will reach out to Inscopix to support their platform as well. Acquisition Tools \u00b6 Daniel Aharoni's lab has developed iterations of the UCLA Miniscope platform. Based on interviews, we have found labs using the two most recent versions including Miniscope DAQ V3 and Miniscope DAQ V4 . Labs also use the Bonsai OpenEphys tool for data acquisition with the UCLA miniscope. Inscopix provides the Inscopix Data Acquisition Software (IDAS) for the nVista and nVoke systems. Preprocessing Tools \u00b6 The preprocessing workflow for miniscope imaging includes denoising, motion correction, cell segmentation, and calcium event extraction (sometimes described as \"deconvolution\" or \"spike inference\"). For the UCLA Miniscopes, the following analysis packages are commonly used: (Package, Developer [Affiliation], Programming Language) Miniscope Denoising , Daniel Aharoni (UCLA), Python NoRMCorre , Flatiron Institute, MATLAB CNMF-E , Pengcheng Zhou (Liam Paninski\u2019s Lab, Columbia University), MATLAB CaImAn , Flatiron Institute, Python miniscoPy , Guillaume Viejo (Adrien Peyrache\u2019s Lab, McGill University), Python MIN1PIPE , Jinghao Lu (Fan Wang\u2019s Lab, MIT), MATLAB CIAtah , Biafra Ahanonu, MATLAB MiniAn , Phil Dong (Denise Cai's Lab, Mount Sinai), Python MiniscopeAnalysis , Guillaume Etter (Sylvain Williams\u2019 Lab, McGill University), MATLAB PIMPN , Guillaume Etter (Sylvain Williams\u2019 Lab, McGill University), Python CellReg , Liron Sheintuch (Yaniv Ziv\u2019s Lab, Weizmann Institute of Science), MATLAB Inscopix Data Processing Software (IDPS) Inscopix Multimodal Image Registration and Analysis (MIRA) Based on interviews with UCLA and Inscopix miniscope users and developers, each research lab uses a different preprocessing workflow. These custom workflows are often closed source and not tracked with version control software. For the preprocessing tools that are open source, they are often developed by an individual during their training period and lack funding for long term maintenance. These factors result in a lack of standardization for miniscope preprocessing tools, which is a major obstacle to adoption for new labs. Table Architecture \u00b6 Each of the DataJoint Elements are a set of tables for common neuroinformatics modalities to organize, preprocess, and analyze data. Each node in the following diagram is either a table in the Element itself or a table that would be connected to the Element. Upstream: - Element Miniscope connects to a Session table, which is modeled in our workflow pipeline . - Although not requried, most choose to connect Session to a Subject table for managing research subjects. miniscope schema: Tables related to importing, analyzing, and exporting miniscope data: + Session : An experimental session where each recording describes a complete 3D dataset from one recording session. + Recording : A table containing information about the equipment used (e.g. the acquisition hardware information). + RecordingInfo : The metadata about this recording from the Miniscope DAQ software (e.g. frame rate, number of channels, frames, etc.). + MotionCorrection : Information about motion correction performed on a recording. + MotionCorrection.RigidMotionCorrection : Details of the rigid motion correction (e.g. shifting in x, y). + MotionCorrection.NonRigidMotionCorrection and MotionCorrection.Block : These tables are used to describe the non-rigid motion correction. + MotionCorrection.Summary : Ssummary images after motion correction (e.g. average image, correlation image, etc.). + Segmentation : This table specifies the segmentation step and its outputs, following the motion correction step. + Segmentation.Mask : This table contains the image mask for the segmented region of interest. + MaskClassification : This table contains informmation about the classification of Segmentation.Mask into a type (e.g. soma, axon, dendrite, artifact, etc.). + Fluorescence : The output fluorescence traces extracted from each Segmentation.Mask . + ActivityExtractionMethod : A record of the activity extraction method (e.g. deconvolution) applied on the fluorescence trace. + Activity : The computed neuronal activity trace from fluorescence trace (e.g. spikes). Key Partnerships \u00b6 Until recently, DataJoint had not been used for miniscope pipelines. However, labs we have contacted have been eager to engage and adopt DataJoint-based workflows in their labs. Adrien Peyrache Lab, McGill University Peyman Golshani Lab, UCLA Daniel Aharoni Lab, UCLA Anne Churchland Lab, UCLA Fan Wang Lab, MIT Antoine Adamantidis Lab, University of Bern Manolis Froudaraki Lab, FORTH Allan Basbaum Lab, UCSF Pipeline Development \u00b6 With assistance from Peyman Golshani\u2019s Lab (UCLA) we have added support for the UCLA Miniscope DAQ V3 acquisition tool and MiniscopeAnalysis preprocessing tool in element-miniscope and workflow-miniscope . They have provided example data for development, and will begin validating in March 2021. Based on interviews, we are considering adding support for the tools listed below. The deciding factors include the number of users, long term support, quality controls, and python programming language (so that the preprocessing tool can be triggered within the element). Acquisition tools + Miniscope DAQ V4 + Inscopix Data Acquisition Software (IDAS) Preprocessing tools + Inscopix Data Processing Software (IDPS) + Inscopix Multimodal Image Registration and Analysis (MIRA) + MiniAn + CaImAn + CNMF-E + CellReg", "title": "Concepts"}, {"location": "concepts/#concepts", "text": "", "title": "Concepts"}, {"location": "concepts/#miniscopes-in-neuroscience-research", "text": "Miniature fluorescence microscopes (miniscopes) are a head-mounted calcium imaging full-frame video modality first introduced in 2005 by Mark Schnitzer's lab ( Flusberg et al., Optics Letters 2005 ). Due to their light weight, these miniscopes allow measuring the dynamic activity of populations of cortical neurons in freely behaving animals. In 2011, Inscopix Inc. was founded to support one-photon miniscopes as a commercial neuroscience research platform, providing proprietary hardware, acquisition software, and analysis software. Today, they estimate their active user base is 491 labs with a total of 1179 installs. An open-source alternative was launched by a UCLA team led by Daniel Aharoni and Peyman Golshani ( Cai et al., Nature 2016 ; Aharoni and Hoogland, Frontiers in Cellular Neuroscience 2019 ). In our conversation with Dr. Aharoni, he estimated about 700 labs currently using the UCLA system alone. The Inscopix user base is smaller but more established. Several two-photon miniscopes have been developed but lack widespread adoption likely due to the expensive hardware required for the two-photon excitation ( Helmchen et al., Neuron 2001 ; Zong et al., Nature Methods 2017 ; Aharoni and Hoogland, Frontiers in Cellular Neuroscience 2019 ). Due to the low costs and ability to record during natural behaviors, one-photon miniscope imaging appears to be the fastest growing calcium imaging modality in the field today. In Year 1, we focused our efforts on supporting the UCLA platform due its fast growth and deficiency of standardization in acquisition and processing pipelines. In future phases, we will reach out to Inscopix to support their platform as well.", "title": "Miniscopes in Neuroscience Research"}, {"location": "concepts/#acquisition-tools", "text": "Daniel Aharoni's lab has developed iterations of the UCLA Miniscope platform. Based on interviews, we have found labs using the two most recent versions including Miniscope DAQ V3 and Miniscope DAQ V4 . Labs also use the Bonsai OpenEphys tool for data acquisition with the UCLA miniscope. Inscopix provides the Inscopix Data Acquisition Software (IDAS) for the nVista and nVoke systems.", "title": "Acquisition Tools"}, {"location": "concepts/#preprocessing-tools", "text": "The preprocessing workflow for miniscope imaging includes denoising, motion correction, cell segmentation, and calcium event extraction (sometimes described as \"deconvolution\" or \"spike inference\"). For the UCLA Miniscopes, the following analysis packages are commonly used: (Package, Developer [Affiliation], Programming Language) Miniscope Denoising , Daniel Aharoni (UCLA), Python NoRMCorre , Flatiron Institute, MATLAB CNMF-E , Pengcheng Zhou (Liam Paninski\u2019s Lab, Columbia University), MATLAB CaImAn , Flatiron Institute, Python miniscoPy , Guillaume Viejo (Adrien Peyrache\u2019s Lab, McGill University), Python MIN1PIPE , Jinghao Lu (Fan Wang\u2019s Lab, MIT), MATLAB CIAtah , Biafra Ahanonu, MATLAB MiniAn , Phil Dong (Denise Cai's Lab, Mount Sinai), Python MiniscopeAnalysis , Guillaume Etter (Sylvain Williams\u2019 Lab, McGill University), MATLAB PIMPN , Guillaume Etter (Sylvain Williams\u2019 Lab, McGill University), Python CellReg , Liron Sheintuch (Yaniv Ziv\u2019s Lab, Weizmann Institute of Science), MATLAB Inscopix Data Processing Software (IDPS) Inscopix Multimodal Image Registration and Analysis (MIRA) Based on interviews with UCLA and Inscopix miniscope users and developers, each research lab uses a different preprocessing workflow. These custom workflows are often closed source and not tracked with version control software. For the preprocessing tools that are open source, they are often developed by an individual during their training period and lack funding for long term maintenance. These factors result in a lack of standardization for miniscope preprocessing tools, which is a major obstacle to adoption for new labs.", "title": "Preprocessing Tools"}, {"location": "concepts/#table-architecture", "text": "Each of the DataJoint Elements are a set of tables for common neuroinformatics modalities to organize, preprocess, and analyze data. Each node in the following diagram is either a table in the Element itself or a table that would be connected to the Element. Upstream: - Element Miniscope connects to a Session table, which is modeled in our workflow pipeline . - Although not requried, most choose to connect Session to a Subject table for managing research subjects. miniscope schema: Tables related to importing, analyzing, and exporting miniscope data: + Session : An experimental session where each recording describes a complete 3D dataset from one recording session. + Recording : A table containing information about the equipment used (e.g. the acquisition hardware information). + RecordingInfo : The metadata about this recording from the Miniscope DAQ software (e.g. frame rate, number of channels, frames, etc.). + MotionCorrection : Information about motion correction performed on a recording. + MotionCorrection.RigidMotionCorrection : Details of the rigid motion correction (e.g. shifting in x, y). + MotionCorrection.NonRigidMotionCorrection and MotionCorrection.Block : These tables are used to describe the non-rigid motion correction. + MotionCorrection.Summary : Ssummary images after motion correction (e.g. average image, correlation image, etc.). + Segmentation : This table specifies the segmentation step and its outputs, following the motion correction step. + Segmentation.Mask : This table contains the image mask for the segmented region of interest. + MaskClassification : This table contains informmation about the classification of Segmentation.Mask into a type (e.g. soma, axon, dendrite, artifact, etc.). + Fluorescence : The output fluorescence traces extracted from each Segmentation.Mask . + ActivityExtractionMethod : A record of the activity extraction method (e.g. deconvolution) applied on the fluorescence trace. + Activity : The computed neuronal activity trace from fluorescence trace (e.g. spikes).", "title": "Table Architecture"}, {"location": "concepts/#key-partnerships", "text": "Until recently, DataJoint had not been used for miniscope pipelines. However, labs we have contacted have been eager to engage and adopt DataJoint-based workflows in their labs. Adrien Peyrache Lab, McGill University Peyman Golshani Lab, UCLA Daniel Aharoni Lab, UCLA Anne Churchland Lab, UCLA Fan Wang Lab, MIT Antoine Adamantidis Lab, University of Bern Manolis Froudaraki Lab, FORTH Allan Basbaum Lab, UCSF", "title": "Key Partnerships"}, {"location": "concepts/#pipeline-development", "text": "With assistance from Peyman Golshani\u2019s Lab (UCLA) we have added support for the UCLA Miniscope DAQ V3 acquisition tool and MiniscopeAnalysis preprocessing tool in element-miniscope and workflow-miniscope . They have provided example data for development, and will begin validating in March 2021. Based on interviews, we are considering adding support for the tools listed below. The deciding factors include the number of users, long term support, quality controls, and python programming language (so that the preprocessing tool can be triggered within the element). Acquisition tools + Miniscope DAQ V4 + Inscopix Data Acquisition Software (IDAS) Preprocessing tools + Inscopix Data Processing Software (IDPS) + Inscopix Multimodal Image Registration and Analysis (MIRA) + MiniAn + CaImAn + CNMF-E + CellReg", "title": "Pipeline Development"}, {"location": "tutorials/", "text": "Tutorials \u00b6 Installation \u00b6 Installation of the Element requires an integrated development environment and database. Instructions to setup each of the components can be found on the User Instructions page. These instructions use the example workflow for Element Miniscope , which can be modified for a user's specific experimental requirements. YouTube \u00b6 Our Element Miniscope tutorial gives an overview of the workflow directory as well as core concepts related to Miniscope itself. Notebooks \u00b6 Each of the notebooks in the workflow steps through ways to interact with the Element itself. To try out Elements notebooks in an online Jupyter environment with access to example data, visit CodeBook . (Miniscope notebooks coming soon!) 00-DataDownload highlights how to use DataJoint tools to download a sample model for trying out the Element. 01-Configure helps configure your local DataJoint installation to point to the correct database. 02-WorkflowStructure demonstrates the table architecture of the Element and key DataJoint basics for interacting with these tables. 03-Process steps through adding data to these tables. 05-Visualization demonstrates how to fetch data from the Element to generate figures and label data. 06-Drop provides the steps for dropping all the tables to start fresh. 07-DownstreamAnalysis demonstrates how to perform analyses such as activity alignment and exploratory visualizations", "title": "Tutorials"}, {"location": "tutorials/#tutorials", "text": "", "title": "Tutorials"}, {"location": "tutorials/#installation", "text": "Installation of the Element requires an integrated development environment and database. Instructions to setup each of the components can be found on the User Instructions page. These instructions use the example workflow for Element Miniscope , which can be modified for a user's specific experimental requirements.", "title": "Installation"}, {"location": "tutorials/#youtube", "text": "Our Element Miniscope tutorial gives an overview of the workflow directory as well as core concepts related to Miniscope itself.", "title": "YouTube"}, {"location": "tutorials/#notebooks", "text": "Each of the notebooks in the workflow steps through ways to interact with the Element itself. To try out Elements notebooks in an online Jupyter environment with access to example data, visit CodeBook . (Miniscope notebooks coming soon!) 00-DataDownload highlights how to use DataJoint tools to download a sample model for trying out the Element. 01-Configure helps configure your local DataJoint installation to point to the correct database. 02-WorkflowStructure demonstrates the table architecture of the Element and key DataJoint basics for interacting with these tables. 03-Process steps through adding data to these tables. 05-Visualization demonstrates how to fetch data from the Element to generate figures and label data. 06-Drop provides the steps for dropping all the tables to start fresh. 07-DownstreamAnalysis demonstrates how to perform analyses such as activity alignment and exploratory visualizations", "title": "Notebooks"}, {"location": "about/changelog/", "text": "Changelog \u00b6 Observes Semantic Versioning standard and Keep a Changelog convention. 0.1.3 - 2022-10-11 \u00b6 Update - CICD workflows for PyPI release 0.1.2 - 2022-05-10 \u00b6 Add - Load data acquired with Miniscope-DAQ-V4 Add - Load data analyzed with CaImAn Add - Trigger CaImAn analysis Remove - Load data analyzed with MiniscopeAnalysis Add - Adopted black formatting into code base 0.1.1 - 2021-04-01 \u00b6 Add - Load data acquired with Miniscope-DAQ-V3 Add - Load data analyzed with MiniscopeAnalysis", "title": "Changelog"}, {"location": "about/changelog/#changelog", "text": "Observes Semantic Versioning standard and Keep a Changelog convention.", "title": "Changelog"}, {"location": "about/changelog/#013-2022-10-11", "text": "Update - CICD workflows for PyPI release", "title": "0.1.3 - 2022-10-11"}, {"location": "about/changelog/#012-2022-05-10", "text": "Add - Load data acquired with Miniscope-DAQ-V4 Add - Load data analyzed with CaImAn Add - Trigger CaImAn analysis Remove - Load data analyzed with MiniscopeAnalysis Add - Adopted black formatting into code base", "title": "0.1.2 - 2022-05-10"}, {"location": "about/changelog/#011-2021-04-01", "text": "Add - Load data acquired with Miniscope-DAQ-V3 Add - Load data analyzed with MiniscopeAnalysis", "title": "0.1.1 - 2021-04-01"}, {"location": "api/element_miniscope/__init__/", "text": "", "title": "__init__.py"}, {"location": "api/element_miniscope/miniscope/", "text": "Curation \u00b6 Bases: dj . Manual Source code in element_miniscope/miniscope.py 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 @schema class Curation ( dj . Manual ): definition = \"\"\" # Different rounds of curation performed on the processing results of the data # (no-curation can also be included here) -> Processing curation_id: int --- curation_time: datetime # time of generation of these curated results curation_output_dir: varchar(255) # output directory of the curated results, # relative to root data directory manual_curation: bool # has manual curation been performed? curation_note='': varchar(2000) \"\"\" def create1_from_processing_task ( self , key , is_curated = False , curation_note = \"\" ): \"\"\" Given a \"ProcessingTask\", create a new corresponding \"Curation\" \"\"\" if key not in Processing (): raise ValueError ( f \"No corresponding entry in Processing available for: \" f \" { key } ; run `Processing.populate(key)`\" ) output_dir = ( ProcessingTask & key ) . fetch1 ( \"processing_output_dir\" ) method , imaging_dataset = get_loader_result ( key , ProcessingTask ) if method == \"caiman\" : caiman_dataset = imaging_dataset curation_time = caiman_dataset . creation_time else : raise NotImplementedError ( \"Unknown method: {} \" . format ( method )) # Synthesize curation_id curation_id = ( dj . U () . aggr ( self & key , n = \"ifnull(max(curation_id)+1,1)\" ) . fetch1 ( \"n\" ) ) self . insert1 ( { ** key , \"curation_id\" : curation_id , \"curation_time\" : curation_time , \"curation_output_dir\" : output_dir , \"manual_curation\" : is_curated , \"curation_note\" : curation_note , } ) create1_from_processing_task ( key , is_curated = False , curation_note = '' ) \u00b6 Given a \"ProcessingTask\", create a new corresponding \"Curation\" Source code in element_miniscope/miniscope.py 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 def create1_from_processing_task ( self , key , is_curated = False , curation_note = \"\" ): \"\"\" Given a \"ProcessingTask\", create a new corresponding \"Curation\" \"\"\" if key not in Processing (): raise ValueError ( f \"No corresponding entry in Processing available for: \" f \" { key } ; run `Processing.populate(key)`\" ) output_dir = ( ProcessingTask & key ) . fetch1 ( \"processing_output_dir\" ) method , imaging_dataset = get_loader_result ( key , ProcessingTask ) if method == \"caiman\" : caiman_dataset = imaging_dataset curation_time = caiman_dataset . creation_time else : raise NotImplementedError ( \"Unknown method: {} \" . format ( method )) # Synthesize curation_id curation_id = ( dj . U () . aggr ( self & key , n = \"ifnull(max(curation_id)+1,1)\" ) . fetch1 ( \"n\" ) ) self . insert1 ( { ** key , \"curation_id\" : curation_id , \"curation_time\" : curation_time , \"curation_output_dir\" : output_dir , \"manual_curation\" : is_curated , \"curation_note\" : curation_note , } ) MotionCorrection \u00b6 Bases: dj . Imported Source code in element_miniscope/miniscope.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 @schema class MotionCorrection ( dj . Imported ): definition = \"\"\" -> Curation --- -> Channel.proj(motion_correct_channel='channel') # channel used for # motion correction \"\"\" class RigidMotionCorrection ( dj . Part ): definition = \"\"\" -> master --- outlier_frames=null : longblob # mask with true for frames with outlier shifts # (already corrected) y_shifts : longblob # (pixels) y motion correction shifts x_shifts : longblob # (pixels) x motion correction shifts y_std : float # (pixels) standard deviation of # y shifts across all frames x_std : float # (pixels) standard deviation of # x shifts across all frames \"\"\" class NonRigidMotionCorrection ( dj . Part ): \"\"\" Piece-wise rigid motion correction \"\"\" definition = \"\"\" -> master --- outlier_frames=null : longblob # mask with true for frames with # outlier shifts (already corrected) block_height : int # (pixels) block_width : int # (pixels) block_count_y : int # number of blocks tiled in the # y direction block_count_x : int # number of blocks tiled in the # x direction \"\"\" class Block ( dj . Part ): definition = \"\"\" # FOV-tiled blocks used for non-rigid motion correction -> master.NonRigidMotionCorrection block_id : int --- block_y : longblob # (y_start, y_end) in pixel of this block block_x : longblob # (x_start, x_end) in pixel of this block y_shifts : longblob # (pixels) y motion correction shifts for # every frame x_shifts : longblob # (pixels) x motion correction shifts for # every frame y_std : float # (pixels) standard deviation of y shifts # across all frames x_std : float # (pixels) standard deviation of x shifts # across all frames \"\"\" class Summary ( dj . Part ): definition = \"\"\" # summary images for each field and channel after corrections -> master --- ref_image=null : longblob # image used as alignment template average_image : longblob # mean of registered frames correlation_image=null : longblob # correlation map # (computed during cell detection) max_proj_image=null : longblob # max of registered frames \"\"\" def make ( self , key ): method , loaded_result = get_loader_result ( key , ProcessingTask ) if method == \"caiman\" : loaded_caiman = loaded_result self . insert1 ( { ** key , \"motion_correct_channel\" : loaded_caiman . alignment_channel } ) # -- rigid motion correction -- if not loaded_caiman . params . motion [ \"pw_rigid\" ]: rigid_correction = { ** key , \"x_shifts\" : loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 0 ], \"y_shifts\" : loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 1 ], \"x_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 0 ] ), \"y_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 1 ] ), \"outlier_frames\" : None , } self . RigidMotionCorrection . insert1 ( rigid_correction ) # -- non-rigid motion correction -- else : nonrigid_correction = { ** key , \"block_height\" : ( loaded_caiman . params . motion [ \"strides\" ][ 0 ] + loaded_caiman . params . motion [ \"overlaps\" ][ 0 ] ), \"block_width\" : ( loaded_caiman . params . motion [ \"strides\" ][ 1 ] + loaded_caiman . params . motion [ \"overlaps\" ][ 1 ] ), \"block_count_x\" : len ( set ( loaded_caiman . motion_correction [ \"coord_shifts_els\" ][:, 0 ]) ), \"block_count_y\" : len ( set ( loaded_caiman . motion_correction [ \"coord_shifts_els\" ][:, 2 ]) ), \"outlier_frames\" : None , } nonrigid_blocks = [] for b_id in range ( len ( loaded_caiman . motion_correction [ \"x_shifts_els\" ][ 0 , :]) ): nonrigid_blocks . append ( { ** key , \"block_id\" : b_id , \"block_x\" : np . arange ( * loaded_caiman . motion_correction [ \"coord_shifts_els\" ][ b_id , 0 : 2 ] ), \"block_y\" : np . arange ( * loaded_caiman . motion_correction [ \"coord_shifts_els\" ][ b_id , 2 : 4 ] ), \"x_shifts\" : loaded_caiman . motion_correction [ \"x_shifts_els\" ][ :, b_id ], \"y_shifts\" : loaded_caiman . motion_correction [ \"y_shifts_els\" ][ :, b_id ], \"x_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"x_shifts_els\" ][:, b_id ] ), \"y_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"y_shifts_els\" ][:, b_id ] ), } ) self . NonRigidMotionCorrection . insert1 ( nonrigid_correction ) self . Block . insert ( nonrigid_blocks ) # -- summary images -- summary_images = { ** key , \"ref_image\" : loaded_caiman . motion_correction [ \"reference_image\" ][ ... ][ np . newaxis , ... ], \"average_image\" : loaded_caiman . motion_correction [ \"average_image\" ][ ... ][ np . newaxis , ... ], \"correlation_image\" : loaded_caiman . motion_correction [ \"correlation_image\" ][ ... ][ np . newaxis , ... ], \"max_proj_image\" : loaded_caiman . motion_correction [ \"max_image\" ][ ... ][ np . newaxis , ... ], } self . Summary . insert1 ( summary_images ) else : raise NotImplementedError ( \"Unknown/unimplemented method: {} \" . format ( method )) NonRigidMotionCorrection \u00b6 Bases: dj . Part Piece-wise rigid motion correction Source code in element_miniscope/miniscope.py 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 class NonRigidMotionCorrection ( dj . Part ): \"\"\" Piece-wise rigid motion correction \"\"\" definition = \"\"\" -> master --- outlier_frames=null : longblob # mask with true for frames with # outlier shifts (already corrected) block_height : int # (pixels) block_width : int # (pixels) block_count_y : int # number of blocks tiled in the # y direction block_count_x : int # number of blocks tiled in the # x direction \"\"\" activate ( miniscope_schema_name , * , create_schema = True , create_tables = True , linking_module = None ) \u00b6 Activate this schema. Parameters: Name Type Description Default miniscope_schema_name str schema name on the database server required create_schema bool when True (default), create schema in the database if it does not yet exist. True create_tables bool when True (default), create tables in the database if they do not yet exist. True linking_module str a module name or a module containing the required dependencies. None Dependencies: Upstream tables Session: parent table to Recording, identifying a recording session. Equipment: Reference table for Recording, specifying the acquisition equipment. AnatomicalLocation: Reference table for RecordingLocation, specifying the brain location where the recording is acquired. Functions get_miniscope_root_data_dir(): Returns absolute path for root data director(y/ies) with all subject/sessions data, as (list of) string(s). get_session_directory(session_key: dict) Returns the session directory with all data for the session in session_key, as a string. get_processed_root_data_dir(): Returns absolute path for all processed data as a string. Source code in element_miniscope/miniscope.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def activate ( miniscope_schema_name , * , create_schema = True , create_tables = True , linking_module = None , ): \"\"\"Activate this schema. Args: miniscope_schema_name (str): schema name on the database server create_schema (bool): when True (default), create schema in the database if it does not yet exist. create_tables (bool): when True (default), create tables in the database if they do not yet exist. linking_module (str): a module name or a module containing the required dependencies. Dependencies: Upstream tables: Session: parent table to Recording, identifying a recording session. Equipment: Reference table for Recording, specifying the acquisition equipment. AnatomicalLocation: Reference table for RecordingLocation, specifying the brain location where the recording is acquired. Functions: get_miniscope_root_data_dir(): Returns absolute path for root data director(y/ies) with all subject/sessions data, as (list of) string(s). get_session_directory(session_key: dict) Returns the session directory with all data for the session in session_key, as a string. get_processed_root_data_dir(): Returns absolute path for all processed data as a string. \"\"\" if isinstance ( linking_module , str ): linking_module = importlib . import_module ( linking_module ) assert inspect . ismodule ( linking_module ), \"The argument 'dependency' must be a module's name or a module\" global _linking_module _linking_module = linking_module schema . activate ( miniscope_schema_name , create_schema = create_schema , create_tables = create_tables , add_objects = _linking_module . __dict__ , ) get_loader_result ( key , table ) \u00b6 Retrieve the loaded processed imaging results from the loader (e.g. caiman, etc.) :param key: the key to one entry of ProcessingTask or Curation :param table: the class defining the table to retrieve the loaded results from (e.g. ProcessingTask, Curation) :return: a loader object of the loaded results (e.g. caiman.CaImAn, etc.) Source code in element_miniscope/miniscope.py 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 def get_loader_result ( key , table ): \"\"\" Retrieve the loaded processed imaging results from the loader (e.g. caiman, etc.) :param key: the `key` to one entry of ProcessingTask or Curation :param table: the class defining the table to retrieve the loaded results from (e.g. ProcessingTask, Curation) :return: a loader object of the loaded results (e.g. caiman.CaImAn, etc.) \"\"\" method , output_dir = ( ProcessingParamSet * table & key ) . fetch1 ( \"processing_method\" , _table_attribute_mapper [ table . __name__ ] ) output_dir = find_full_path ( get_miniscope_root_data_dir (), output_dir ) if method == \"caiman\" : from element_interface import caiman_loader loaded_output = caiman_loader . CaImAn ( output_dir ) else : raise NotImplementedError ( \"Unknown/unimplemented method: {} \" . format ( method )) return method , loaded_output get_miniscope_root_data_dir () \u00b6 All data paths, directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations). get_miniscope_root_data_dir() -> list This user-provided function retrieves the possible root data directories containing the miniscope data for all subjects and sessions (e.g. acquired Miniscope-DAQ-V4 raw files, output files from processing routines, etc.). :return: a string for full path to the root data directory, or list of strings for possible root data directories Source code in element_miniscope/miniscope.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_miniscope_root_data_dir () -> list : \"\"\" All data paths, directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations). get_miniscope_root_data_dir() -> list This user-provided function retrieves the possible root data directories containing the miniscope data for all subjects and sessions (e.g. acquired Miniscope-DAQ-V4 raw files, output files from processing routines, etc.). :return: a string for full path to the root data directory, or list of strings for possible root data directories \"\"\" root_directories = _linking_module . get_miniscope_root_data_dir () if isinstance ( root_directories , ( str , pathlib . Path )): root_directories = [ root_directories ] if hasattr ( _linking_module , \"get_processed_root_data_dir\" ): root_directories . append ( _linking_module . get_processed_root_data_dir ()) return root_directories get_processed_root_data_dir () \u00b6 get_processed_root_data_dir() -> str: Retrieves the root directory for all processed data :return: a string for full path to the root directory for processed data Source code in element_miniscope/miniscope.py 104 105 106 107 108 109 110 111 112 113 114 def get_processed_root_data_dir () -> str : \"\"\" get_processed_root_data_dir() -> str: Retrieves the root directory for all processed data :return: a string for full path to the root directory for processed data \"\"\" if hasattr ( _linking_module , \"get_processed_root_data_dir\" ): return _linking_module . get_processed_root_data_dir () else : return get_miniscope_root_data_dir ()[ 0 ] get_session_directory ( session_key ) \u00b6 get_session_directory(session_key: dict) -> str Retrieve the session directory containing the recorded data for a given session :param session_key: a dictionary of one session key :return: a string for relative or full path to the session directory Source code in element_miniscope/miniscope.py 93 94 95 96 97 98 99 100 101 def get_session_directory ( session_key : dict ) -> str : \"\"\" get_session_directory(session_key: dict) -> str Retrieve the session directory containing the recorded data for a given session :param session_key: a dictionary of one session `key` :return: a string for relative or full path to the session directory \"\"\" return _linking_module . get_session_directory ( session_key )", "title": "miniscope.py"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Curation", "text": "Bases: dj . Manual Source code in element_miniscope/miniscope.py 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 @schema class Curation ( dj . Manual ): definition = \"\"\" # Different rounds of curation performed on the processing results of the data # (no-curation can also be included here) -> Processing curation_id: int --- curation_time: datetime # time of generation of these curated results curation_output_dir: varchar(255) # output directory of the curated results, # relative to root data directory manual_curation: bool # has manual curation been performed? curation_note='': varchar(2000) \"\"\" def create1_from_processing_task ( self , key , is_curated = False , curation_note = \"\" ): \"\"\" Given a \"ProcessingTask\", create a new corresponding \"Curation\" \"\"\" if key not in Processing (): raise ValueError ( f \"No corresponding entry in Processing available for: \" f \" { key } ; run `Processing.populate(key)`\" ) output_dir = ( ProcessingTask & key ) . fetch1 ( \"processing_output_dir\" ) method , imaging_dataset = get_loader_result ( key , ProcessingTask ) if method == \"caiman\" : caiman_dataset = imaging_dataset curation_time = caiman_dataset . creation_time else : raise NotImplementedError ( \"Unknown method: {} \" . format ( method )) # Synthesize curation_id curation_id = ( dj . U () . aggr ( self & key , n = \"ifnull(max(curation_id)+1,1)\" ) . fetch1 ( \"n\" ) ) self . insert1 ( { ** key , \"curation_id\" : curation_id , \"curation_time\" : curation_time , \"curation_output_dir\" : output_dir , \"manual_curation\" : is_curated , \"curation_note\" : curation_note , } )", "title": "Curation"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.Curation.create1_from_processing_task", "text": "Given a \"ProcessingTask\", create a new corresponding \"Curation\" Source code in element_miniscope/miniscope.py 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 def create1_from_processing_task ( self , key , is_curated = False , curation_note = \"\" ): \"\"\" Given a \"ProcessingTask\", create a new corresponding \"Curation\" \"\"\" if key not in Processing (): raise ValueError ( f \"No corresponding entry in Processing available for: \" f \" { key } ; run `Processing.populate(key)`\" ) output_dir = ( ProcessingTask & key ) . fetch1 ( \"processing_output_dir\" ) method , imaging_dataset = get_loader_result ( key , ProcessingTask ) if method == \"caiman\" : caiman_dataset = imaging_dataset curation_time = caiman_dataset . creation_time else : raise NotImplementedError ( \"Unknown method: {} \" . format ( method )) # Synthesize curation_id curation_id = ( dj . U () . aggr ( self & key , n = \"ifnull(max(curation_id)+1,1)\" ) . fetch1 ( \"n\" ) ) self . insert1 ( { ** key , \"curation_id\" : curation_id , \"curation_time\" : curation_time , \"curation_output_dir\" : output_dir , \"manual_curation\" : is_curated , \"curation_note\" : curation_note , } )", "title": "create1_from_processing_task()"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection", "text": "Bases: dj . Imported Source code in element_miniscope/miniscope.py 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 @schema class MotionCorrection ( dj . Imported ): definition = \"\"\" -> Curation --- -> Channel.proj(motion_correct_channel='channel') # channel used for # motion correction \"\"\" class RigidMotionCorrection ( dj . Part ): definition = \"\"\" -> master --- outlier_frames=null : longblob # mask with true for frames with outlier shifts # (already corrected) y_shifts : longblob # (pixels) y motion correction shifts x_shifts : longblob # (pixels) x motion correction shifts y_std : float # (pixels) standard deviation of # y shifts across all frames x_std : float # (pixels) standard deviation of # x shifts across all frames \"\"\" class NonRigidMotionCorrection ( dj . Part ): \"\"\" Piece-wise rigid motion correction \"\"\" definition = \"\"\" -> master --- outlier_frames=null : longblob # mask with true for frames with # outlier shifts (already corrected) block_height : int # (pixels) block_width : int # (pixels) block_count_y : int # number of blocks tiled in the # y direction block_count_x : int # number of blocks tiled in the # x direction \"\"\" class Block ( dj . Part ): definition = \"\"\" # FOV-tiled blocks used for non-rigid motion correction -> master.NonRigidMotionCorrection block_id : int --- block_y : longblob # (y_start, y_end) in pixel of this block block_x : longblob # (x_start, x_end) in pixel of this block y_shifts : longblob # (pixels) y motion correction shifts for # every frame x_shifts : longblob # (pixels) x motion correction shifts for # every frame y_std : float # (pixels) standard deviation of y shifts # across all frames x_std : float # (pixels) standard deviation of x shifts # across all frames \"\"\" class Summary ( dj . Part ): definition = \"\"\" # summary images for each field and channel after corrections -> master --- ref_image=null : longblob # image used as alignment template average_image : longblob # mean of registered frames correlation_image=null : longblob # correlation map # (computed during cell detection) max_proj_image=null : longblob # max of registered frames \"\"\" def make ( self , key ): method , loaded_result = get_loader_result ( key , ProcessingTask ) if method == \"caiman\" : loaded_caiman = loaded_result self . insert1 ( { ** key , \"motion_correct_channel\" : loaded_caiman . alignment_channel } ) # -- rigid motion correction -- if not loaded_caiman . params . motion [ \"pw_rigid\" ]: rigid_correction = { ** key , \"x_shifts\" : loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 0 ], \"y_shifts\" : loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 1 ], \"x_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 0 ] ), \"y_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"shifts_rig\" ][:, 1 ] ), \"outlier_frames\" : None , } self . RigidMotionCorrection . insert1 ( rigid_correction ) # -- non-rigid motion correction -- else : nonrigid_correction = { ** key , \"block_height\" : ( loaded_caiman . params . motion [ \"strides\" ][ 0 ] + loaded_caiman . params . motion [ \"overlaps\" ][ 0 ] ), \"block_width\" : ( loaded_caiman . params . motion [ \"strides\" ][ 1 ] + loaded_caiman . params . motion [ \"overlaps\" ][ 1 ] ), \"block_count_x\" : len ( set ( loaded_caiman . motion_correction [ \"coord_shifts_els\" ][:, 0 ]) ), \"block_count_y\" : len ( set ( loaded_caiman . motion_correction [ \"coord_shifts_els\" ][:, 2 ]) ), \"outlier_frames\" : None , } nonrigid_blocks = [] for b_id in range ( len ( loaded_caiman . motion_correction [ \"x_shifts_els\" ][ 0 , :]) ): nonrigid_blocks . append ( { ** key , \"block_id\" : b_id , \"block_x\" : np . arange ( * loaded_caiman . motion_correction [ \"coord_shifts_els\" ][ b_id , 0 : 2 ] ), \"block_y\" : np . arange ( * loaded_caiman . motion_correction [ \"coord_shifts_els\" ][ b_id , 2 : 4 ] ), \"x_shifts\" : loaded_caiman . motion_correction [ \"x_shifts_els\" ][ :, b_id ], \"y_shifts\" : loaded_caiman . motion_correction [ \"y_shifts_els\" ][ :, b_id ], \"x_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"x_shifts_els\" ][:, b_id ] ), \"y_std\" : np . nanstd ( loaded_caiman . motion_correction [ \"y_shifts_els\" ][:, b_id ] ), } ) self . NonRigidMotionCorrection . insert1 ( nonrigid_correction ) self . Block . insert ( nonrigid_blocks ) # -- summary images -- summary_images = { ** key , \"ref_image\" : loaded_caiman . motion_correction [ \"reference_image\" ][ ... ][ np . newaxis , ... ], \"average_image\" : loaded_caiman . motion_correction [ \"average_image\" ][ ... ][ np . newaxis , ... ], \"correlation_image\" : loaded_caiman . motion_correction [ \"correlation_image\" ][ ... ][ np . newaxis , ... ], \"max_proj_image\" : loaded_caiman . motion_correction [ \"max_image\" ][ ... ][ np . newaxis , ... ], } self . Summary . insert1 ( summary_images ) else : raise NotImplementedError ( \"Unknown/unimplemented method: {} \" . format ( method ))", "title": "MotionCorrection"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.MotionCorrection.NonRigidMotionCorrection", "text": "Bases: dj . Part Piece-wise rigid motion correction Source code in element_miniscope/miniscope.py 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 class NonRigidMotionCorrection ( dj . Part ): \"\"\" Piece-wise rigid motion correction \"\"\" definition = \"\"\" -> master --- outlier_frames=null : longblob # mask with true for frames with # outlier shifts (already corrected) block_height : int # (pixels) block_width : int # (pixels) block_count_y : int # number of blocks tiled in the # y direction block_count_x : int # number of blocks tiled in the # x direction \"\"\"", "title": "NonRigidMotionCorrection"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.activate", "text": "Activate this schema. Parameters: Name Type Description Default miniscope_schema_name str schema name on the database server required create_schema bool when True (default), create schema in the database if it does not yet exist. True create_tables bool when True (default), create tables in the database if they do not yet exist. True linking_module str a module name or a module containing the required dependencies. None Dependencies: Upstream tables Session: parent table to Recording, identifying a recording session. Equipment: Reference table for Recording, specifying the acquisition equipment. AnatomicalLocation: Reference table for RecordingLocation, specifying the brain location where the recording is acquired. Functions get_miniscope_root_data_dir(): Returns absolute path for root data director(y/ies) with all subject/sessions data, as (list of) string(s). get_session_directory(session_key: dict) Returns the session directory with all data for the session in session_key, as a string. get_processed_root_data_dir(): Returns absolute path for all processed data as a string. Source code in element_miniscope/miniscope.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def activate ( miniscope_schema_name , * , create_schema = True , create_tables = True , linking_module = None , ): \"\"\"Activate this schema. Args: miniscope_schema_name (str): schema name on the database server create_schema (bool): when True (default), create schema in the database if it does not yet exist. create_tables (bool): when True (default), create tables in the database if they do not yet exist. linking_module (str): a module name or a module containing the required dependencies. Dependencies: Upstream tables: Session: parent table to Recording, identifying a recording session. Equipment: Reference table for Recording, specifying the acquisition equipment. AnatomicalLocation: Reference table for RecordingLocation, specifying the brain location where the recording is acquired. Functions: get_miniscope_root_data_dir(): Returns absolute path for root data director(y/ies) with all subject/sessions data, as (list of) string(s). get_session_directory(session_key: dict) Returns the session directory with all data for the session in session_key, as a string. get_processed_root_data_dir(): Returns absolute path for all processed data as a string. \"\"\" if isinstance ( linking_module , str ): linking_module = importlib . import_module ( linking_module ) assert inspect . ismodule ( linking_module ), \"The argument 'dependency' must be a module's name or a module\" global _linking_module _linking_module = linking_module schema . activate ( miniscope_schema_name , create_schema = create_schema , create_tables = create_tables , add_objects = _linking_module . __dict__ , )", "title": "activate()"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.get_loader_result", "text": "Retrieve the loaded processed imaging results from the loader (e.g. caiman, etc.) :param key: the key to one entry of ProcessingTask or Curation :param table: the class defining the table to retrieve the loaded results from (e.g. ProcessingTask, Curation) :return: a loader object of the loaded results (e.g. caiman.CaImAn, etc.) Source code in element_miniscope/miniscope.py 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 def get_loader_result ( key , table ): \"\"\" Retrieve the loaded processed imaging results from the loader (e.g. caiman, etc.) :param key: the `key` to one entry of ProcessingTask or Curation :param table: the class defining the table to retrieve the loaded results from (e.g. ProcessingTask, Curation) :return: a loader object of the loaded results (e.g. caiman.CaImAn, etc.) \"\"\" method , output_dir = ( ProcessingParamSet * table & key ) . fetch1 ( \"processing_method\" , _table_attribute_mapper [ table . __name__ ] ) output_dir = find_full_path ( get_miniscope_root_data_dir (), output_dir ) if method == \"caiman\" : from element_interface import caiman_loader loaded_output = caiman_loader . CaImAn ( output_dir ) else : raise NotImplementedError ( \"Unknown/unimplemented method: {} \" . format ( method )) return method , loaded_output", "title": "get_loader_result()"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.get_miniscope_root_data_dir", "text": "All data paths, directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations). get_miniscope_root_data_dir() -> list This user-provided function retrieves the possible root data directories containing the miniscope data for all subjects and sessions (e.g. acquired Miniscope-DAQ-V4 raw files, output files from processing routines, etc.). :return: a string for full path to the root data directory, or list of strings for possible root data directories Source code in element_miniscope/miniscope.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_miniscope_root_data_dir () -> list : \"\"\" All data paths, directories in DataJoint Elements are recommended to be stored as relative paths (posix format), with respect to some user-configured \"root\" directory, which varies from machine to machine (e.g. different mounted drive locations). get_miniscope_root_data_dir() -> list This user-provided function retrieves the possible root data directories containing the miniscope data for all subjects and sessions (e.g. acquired Miniscope-DAQ-V4 raw files, output files from processing routines, etc.). :return: a string for full path to the root data directory, or list of strings for possible root data directories \"\"\" root_directories = _linking_module . get_miniscope_root_data_dir () if isinstance ( root_directories , ( str , pathlib . Path )): root_directories = [ root_directories ] if hasattr ( _linking_module , \"get_processed_root_data_dir\" ): root_directories . append ( _linking_module . get_processed_root_data_dir ()) return root_directories", "title": "get_miniscope_root_data_dir()"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.get_processed_root_data_dir", "text": "get_processed_root_data_dir() -> str: Retrieves the root directory for all processed data :return: a string for full path to the root directory for processed data Source code in element_miniscope/miniscope.py 104 105 106 107 108 109 110 111 112 113 114 def get_processed_root_data_dir () -> str : \"\"\" get_processed_root_data_dir() -> str: Retrieves the root directory for all processed data :return: a string for full path to the root directory for processed data \"\"\" if hasattr ( _linking_module , \"get_processed_root_data_dir\" ): return _linking_module . get_processed_root_data_dir () else : return get_miniscope_root_data_dir ()[ 0 ]", "title": "get_processed_root_data_dir()"}, {"location": "api/element_miniscope/miniscope/#element_miniscope.miniscope.get_session_directory", "text": "get_session_directory(session_key: dict) -> str Retrieve the session directory containing the recorded data for a given session :param session_key: a dictionary of one session key :return: a string for relative or full path to the session directory Source code in element_miniscope/miniscope.py 93 94 95 96 97 98 99 100 101 def get_session_directory ( session_key : dict ) -> str : \"\"\" get_session_directory(session_key: dict) -> str Retrieve the session directory containing the recorded data for a given session :param session_key: a dictionary of one session `key` :return: a string for relative or full path to the session directory \"\"\" return _linking_module . get_session_directory ( session_key )", "title": "get_session_directory()"}, {"location": "api/element_miniscope/version/", "text": "Package metadata", "title": "version.py"}, {"location": "api/workflow_miniscope/__init__/", "text": "", "title": "__init__.py"}, {"location": "api/workflow_miniscope/analysis/", "text": "ActivityAlignment \u00b6 Bases: dj . Computed Source code in workflow_miniscope/analysis.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 @schema class ActivityAlignment ( dj . Computed ): definition = \"\"\" -> ActivityAlignmentCondition --- aligned_timestamps: longblob \"\"\" class AlignedTrialActivity ( dj . Part ): definition = \"\"\" -> master -> miniscope.Activity.Trace -> ActivityAlignmentCondition.Trial --- aligned_trace: longblob # (s) Calcium activity aligned to the event time \"\"\" def make ( self , key ): sess_time , rec_time , nframes , frame_rate = ( miniscope . RecordingInfo * session . Session & key ) . fetch1 ( \"session_datetime\" , \"recording_datetime\" , \"nframes\" , \"fps\" ) # Estimation of frame timestamps with respect to the session-start # (to be replaced by timestamps retrieved from some synchronization routine) rec_start = ( rec_time - sess_time ) . total_seconds () if rec_time else 0 frame_timestamps = np . arange ( nframes ) / frame_rate + rec_start trialized_event_times = trial . get_trialized_alignment_event_times ( key , trial . Trial & ( ActivityAlignmentCondition . Trial & key ) ) min_limit = ( trialized_event_times . event - trialized_event_times . start ) . max () max_limit = ( trialized_event_times . end - trialized_event_times . event ) . max () aligned_timestamps = np . arange ( - min_limit , max_limit , 1 / frame_rate ) nsamples = len ( aligned_timestamps ) trace_keys , activity_traces = ( miniscope . Activity . Trace & key ) . fetch ( \"KEY\" , \"activity_trace\" , order_by = \"mask_id\" ) activity_traces = np . vstack ( activity_traces ) aligned_trial_activities = [] for _ , r in trialized_event_times . iterrows (): if r . event is None or np . isnan ( r . event ): continue alignment_start_idx = int (( r . event - min_limit ) * frame_rate ) roi_aligned_activities = activity_traces [ :, alignment_start_idx : ( alignment_start_idx + nsamples ) ] if roi_aligned_activities . shape [ - 1 ] != nsamples : shape_diff = nsamples - roi_aligned_activities . shape [ - 1 ] roi_aligned_activities = np . pad ( roi_aligned_activities , (( 0 , 0 ), ( 0 , shape_diff )), mode = \"constant\" , constant_values = np . nan , ) aligned_trial_activities . extend ( [ { ** key , ** r . trial_key , ** trace_key , \"aligned_trace\" : aligned_trace } for trace_key , aligned_trace in zip ( trace_keys , roi_aligned_activities ) ] ) self . insert1 ({ ** key , \"aligned_timestamps\" : aligned_timestamps }) self . AlignedTrialActivity . insert ( aligned_trial_activities ) def plot_aligned_activities ( self , key , roi , axs = None , title = None ): \"\"\" Plot event-aligned Calcium activities for all selected trials, and trial-averaged Calcium activity e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc. :param key: key of ActivityAlignment master table :param roi: miniscope segmentation mask :param axs: optional definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8)) :param title: Optional title label \"\"\" import matplotlib.pyplot as plt fig = None if axs is None : fig , ( ax0 , ax1 ) = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 )) else : ax0 , ax1 = axs aligned_timestamps = ( self & key ) . fetch1 ( \"aligned_timestamps\" ) trial_ids , aligned_spikes = ( self . AlignedTrialActivity & key & { \"mask_id\" : roi } ) . fetch ( \"trial_id\" , \"aligned_trace\" , order_by = \"trial_id\" ) aligned_spikes = np . vstack ( aligned_spikes ) ax0 . imshow ( aligned_spikes , cmap = \"inferno\" , interpolation = \"nearest\" , aspect = \"auto\" , extent = ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ], 0 , aligned_spikes . shape [ 0 ], ), ) ax0 . axvline ( x = 0 , linestyle = \"--\" , color = \"white\" ) ax0 . set_axis_off () ax1 . plot ( aligned_timestamps , np . nanmean ( aligned_spikes , axis = 0 )) ax1 . axvline ( x = 0 , linestyle = \"--\" , color = \"black\" ) ax1 . set_xlabel ( \"Time (s)\" ) ax1 . set_xlim ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ]) if title : plt . suptitle ( title ) return fig plot_aligned_activities ( key , roi , axs = None , title = None ) \u00b6 Plot event-aligned Calcium activities for all selected trials, and trial-averaged Calcium activity e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc. :param key: key of ActivityAlignment master table :param roi: miniscope segmentation mask :param axs: optional definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8)) :param title: Optional title label Source code in workflow_miniscope/analysis.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def plot_aligned_activities ( self , key , roi , axs = None , title = None ): \"\"\" Plot event-aligned Calcium activities for all selected trials, and trial-averaged Calcium activity e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc. :param key: key of ActivityAlignment master table :param roi: miniscope segmentation mask :param axs: optional definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8)) :param title: Optional title label \"\"\" import matplotlib.pyplot as plt fig = None if axs is None : fig , ( ax0 , ax1 ) = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 )) else : ax0 , ax1 = axs aligned_timestamps = ( self & key ) . fetch1 ( \"aligned_timestamps\" ) trial_ids , aligned_spikes = ( self . AlignedTrialActivity & key & { \"mask_id\" : roi } ) . fetch ( \"trial_id\" , \"aligned_trace\" , order_by = \"trial_id\" ) aligned_spikes = np . vstack ( aligned_spikes ) ax0 . imshow ( aligned_spikes , cmap = \"inferno\" , interpolation = \"nearest\" , aspect = \"auto\" , extent = ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ], 0 , aligned_spikes . shape [ 0 ], ), ) ax0 . axvline ( x = 0 , linestyle = \"--\" , color = \"white\" ) ax0 . set_axis_off () ax1 . plot ( aligned_timestamps , np . nanmean ( aligned_spikes , axis = 0 )) ax1 . axvline ( x = 0 , linestyle = \"--\" , color = \"black\" ) ax1 . set_xlabel ( \"Time (s)\" ) ax1 . set_xlim ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ]) if title : plt . suptitle ( title ) return fig", "title": "analysis.py"}, {"location": "api/workflow_miniscope/analysis/#workflow_miniscope.analysis.ActivityAlignment", "text": "Bases: dj . Computed Source code in workflow_miniscope/analysis.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 @schema class ActivityAlignment ( dj . Computed ): definition = \"\"\" -> ActivityAlignmentCondition --- aligned_timestamps: longblob \"\"\" class AlignedTrialActivity ( dj . Part ): definition = \"\"\" -> master -> miniscope.Activity.Trace -> ActivityAlignmentCondition.Trial --- aligned_trace: longblob # (s) Calcium activity aligned to the event time \"\"\" def make ( self , key ): sess_time , rec_time , nframes , frame_rate = ( miniscope . RecordingInfo * session . Session & key ) . fetch1 ( \"session_datetime\" , \"recording_datetime\" , \"nframes\" , \"fps\" ) # Estimation of frame timestamps with respect to the session-start # (to be replaced by timestamps retrieved from some synchronization routine) rec_start = ( rec_time - sess_time ) . total_seconds () if rec_time else 0 frame_timestamps = np . arange ( nframes ) / frame_rate + rec_start trialized_event_times = trial . get_trialized_alignment_event_times ( key , trial . Trial & ( ActivityAlignmentCondition . Trial & key ) ) min_limit = ( trialized_event_times . event - trialized_event_times . start ) . max () max_limit = ( trialized_event_times . end - trialized_event_times . event ) . max () aligned_timestamps = np . arange ( - min_limit , max_limit , 1 / frame_rate ) nsamples = len ( aligned_timestamps ) trace_keys , activity_traces = ( miniscope . Activity . Trace & key ) . fetch ( \"KEY\" , \"activity_trace\" , order_by = \"mask_id\" ) activity_traces = np . vstack ( activity_traces ) aligned_trial_activities = [] for _ , r in trialized_event_times . iterrows (): if r . event is None or np . isnan ( r . event ): continue alignment_start_idx = int (( r . event - min_limit ) * frame_rate ) roi_aligned_activities = activity_traces [ :, alignment_start_idx : ( alignment_start_idx + nsamples ) ] if roi_aligned_activities . shape [ - 1 ] != nsamples : shape_diff = nsamples - roi_aligned_activities . shape [ - 1 ] roi_aligned_activities = np . pad ( roi_aligned_activities , (( 0 , 0 ), ( 0 , shape_diff )), mode = \"constant\" , constant_values = np . nan , ) aligned_trial_activities . extend ( [ { ** key , ** r . trial_key , ** trace_key , \"aligned_trace\" : aligned_trace } for trace_key , aligned_trace in zip ( trace_keys , roi_aligned_activities ) ] ) self . insert1 ({ ** key , \"aligned_timestamps\" : aligned_timestamps }) self . AlignedTrialActivity . insert ( aligned_trial_activities ) def plot_aligned_activities ( self , key , roi , axs = None , title = None ): \"\"\" Plot event-aligned Calcium activities for all selected trials, and trial-averaged Calcium activity e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc. :param key: key of ActivityAlignment master table :param roi: miniscope segmentation mask :param axs: optional definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8)) :param title: Optional title label \"\"\" import matplotlib.pyplot as plt fig = None if axs is None : fig , ( ax0 , ax1 ) = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 )) else : ax0 , ax1 = axs aligned_timestamps = ( self & key ) . fetch1 ( \"aligned_timestamps\" ) trial_ids , aligned_spikes = ( self . AlignedTrialActivity & key & { \"mask_id\" : roi } ) . fetch ( \"trial_id\" , \"aligned_trace\" , order_by = \"trial_id\" ) aligned_spikes = np . vstack ( aligned_spikes ) ax0 . imshow ( aligned_spikes , cmap = \"inferno\" , interpolation = \"nearest\" , aspect = \"auto\" , extent = ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ], 0 , aligned_spikes . shape [ 0 ], ), ) ax0 . axvline ( x = 0 , linestyle = \"--\" , color = \"white\" ) ax0 . set_axis_off () ax1 . plot ( aligned_timestamps , np . nanmean ( aligned_spikes , axis = 0 )) ax1 . axvline ( x = 0 , linestyle = \"--\" , color = \"black\" ) ax1 . set_xlabel ( \"Time (s)\" ) ax1 . set_xlim ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ]) if title : plt . suptitle ( title ) return fig", "title": "ActivityAlignment"}, {"location": "api/workflow_miniscope/analysis/#workflow_miniscope.analysis.ActivityAlignment.plot_aligned_activities", "text": "Plot event-aligned Calcium activities for all selected trials, and trial-averaged Calcium activity e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc. :param key: key of ActivityAlignment master table :param roi: miniscope segmentation mask :param axs: optional definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8)) :param title: Optional title label Source code in workflow_miniscope/analysis.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def plot_aligned_activities ( self , key , roi , axs = None , title = None ): \"\"\" Plot event-aligned Calcium activities for all selected trials, and trial-averaged Calcium activity e.g. dF/F, neuropil-corrected dF/F, Calcium events, etc. :param key: key of ActivityAlignment master table :param roi: miniscope segmentation mask :param axs: optional definition of axes for plot. Default is plt.subplots(2, 1, figsize=(12, 8)) :param title: Optional title label \"\"\" import matplotlib.pyplot as plt fig = None if axs is None : fig , ( ax0 , ax1 ) = plt . subplots ( 2 , 1 , figsize = ( 12 , 8 )) else : ax0 , ax1 = axs aligned_timestamps = ( self & key ) . fetch1 ( \"aligned_timestamps\" ) trial_ids , aligned_spikes = ( self . AlignedTrialActivity & key & { \"mask_id\" : roi } ) . fetch ( \"trial_id\" , \"aligned_trace\" , order_by = \"trial_id\" ) aligned_spikes = np . vstack ( aligned_spikes ) ax0 . imshow ( aligned_spikes , cmap = \"inferno\" , interpolation = \"nearest\" , aspect = \"auto\" , extent = ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ], 0 , aligned_spikes . shape [ 0 ], ), ) ax0 . axvline ( x = 0 , linestyle = \"--\" , color = \"white\" ) ax0 . set_axis_off () ax1 . plot ( aligned_timestamps , np . nanmean ( aligned_spikes , axis = 0 )) ax1 . axvline ( x = 0 , linestyle = \"--\" , color = \"black\" ) ax1 . set_xlabel ( \"Time (s)\" ) ax1 . set_xlim ( aligned_timestamps [ 0 ], aligned_timestamps [ - 1 ]) if title : plt . suptitle ( title ) return fig", "title": "plot_aligned_activities()"}, {"location": "api/workflow_miniscope/ingest/", "text": "ingest_alignment ( alignment_csv_path = './user_data/alignments.csv' , skip_duplicates = True , verbose = True ) \u00b6 This is duplicated across wf-array-ephys and wf-calcium-imaging Source code in workflow_miniscope/ingest.py 163 164 165 166 167 168 169 170 171 def ingest_alignment ( alignment_csv_path = \"./user_data/alignments.csv\" , skip_duplicates = True , verbose = True ): \"\"\"This is duplicated across wf-array-ephys and wf-calcium-imaging\"\"\" csvs = [ alignment_csv_path ] tables = [ event . AlignmentEvent ()] ingest_csv_to_table ( csvs , tables , skip_duplicates = skip_duplicates , verbose = verbose ) ingest_events ( recording_csv_path = './user_data/behavior_recordings.csv' , block_csv_path = './user_data/blocks.csv' , trial_csv_path = './user_data/trials.csv' , event_csv_path = './user_data/events.csv' , skip_duplicates = True , verbose = True ) \u00b6 Ingest each level of experiment heirarchy for element-trial recording, block (i.e., phases of trials), trials (repeated units), events (optionally 0-duration occurances within trial). This ingestion function is duplicated across wf-array-ephys and wf-calcium-imaging Source code in workflow_miniscope/ingest.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def ingest_events ( recording_csv_path = \"./user_data/behavior_recordings.csv\" , block_csv_path = \"./user_data/blocks.csv\" , trial_csv_path = \"./user_data/trials.csv\" , event_csv_path = \"./user_data/events.csv\" , skip_duplicates = True , verbose = True , ): \"\"\" Ingest each level of experiment heirarchy for element-trial: recording, block (i.e., phases of trials), trials (repeated units), events (optionally 0-duration occurances within trial). This ingestion function is duplicated across wf-array-ephys and wf-calcium-imaging \"\"\" csvs = [ recording_csv_path , recording_csv_path , block_csv_path , block_csv_path , trial_csv_path , trial_csv_path , trial_csv_path , trial_csv_path , event_csv_path , event_csv_path , event_csv_path , ] tables = [ event . BehaviorRecording (), event . BehaviorRecording . File (), trial . Block (), trial . Block . Attribute (), trial . TrialType (), trial . Trial (), trial . Trial . Attribute (), trial . BlockTrial (), event . EventType (), event . Event (), trial . TrialEvent (), ] ingest_csv_to_table ( csvs , tables , skip_duplicates = skip_duplicates , verbose = verbose , allow_direct_insert = True , ) ingest_subjects ( subject_csv_path = './user_data/subjects.csv' , skip_duplicates = True , verbose = True ) \u00b6 Ingest subjects listed in the subject column of ./user_data/subjects.csv Source code in workflow_miniscope/ingest.py 11 12 13 14 15 16 17 18 19 20 def ingest_subjects ( subject_csv_path = \"./user_data/subjects.csv\" , skip_duplicates = True , verbose = True ): \"\"\" Ingest subjects listed in the subject column of ./user_data/subjects.csv \"\"\" csvs = [ subject_csv_path ] tables = [ subject . Subject ()] ingest_csv_to_table ( csvs , tables , skip_duplicates = skip_duplicates , verbose = verbose ) recursive_search ( key , dictionary ) \u00b6 Search through a nested dictionary for a key and returns its value. If there are more than one key with the same name at different depths, the algorithm returns the value of the least nested key. recursive_search(key, dictionary) :param key: key used to search through a nested dictionary :param dictionary: nested dictionary :return a: value of the input argument key Source code in workflow_miniscope/ingest.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def recursive_search ( key , dictionary ): \"\"\" Search through a nested dictionary for a key and returns its value. If there are more than one key with the same name at different depths, the algorithm returns the value of the least nested key. recursive_search(key, dictionary) :param key: key used to search through a nested dictionary :param dictionary: nested dictionary :return a: value of the input argument `key` \"\"\" if key in dictionary : return dictionary [ key ] for value in dictionary . values (): if isinstance ( value , dict ): a = recursive_search ( key , value ) if a is not None : return a return None", "title": "ingest.py"}, {"location": "api/workflow_miniscope/ingest/#workflow_miniscope.ingest.ingest_alignment", "text": "This is duplicated across wf-array-ephys and wf-calcium-imaging Source code in workflow_miniscope/ingest.py 163 164 165 166 167 168 169 170 171 def ingest_alignment ( alignment_csv_path = \"./user_data/alignments.csv\" , skip_duplicates = True , verbose = True ): \"\"\"This is duplicated across wf-array-ephys and wf-calcium-imaging\"\"\" csvs = [ alignment_csv_path ] tables = [ event . AlignmentEvent ()] ingest_csv_to_table ( csvs , tables , skip_duplicates = skip_duplicates , verbose = verbose )", "title": "ingest_alignment()"}, {"location": "api/workflow_miniscope/ingest/#workflow_miniscope.ingest.ingest_events", "text": "Ingest each level of experiment heirarchy for element-trial recording, block (i.e., phases of trials), trials (repeated units), events (optionally 0-duration occurances within trial). This ingestion function is duplicated across wf-array-ephys and wf-calcium-imaging Source code in workflow_miniscope/ingest.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 def ingest_events ( recording_csv_path = \"./user_data/behavior_recordings.csv\" , block_csv_path = \"./user_data/blocks.csv\" , trial_csv_path = \"./user_data/trials.csv\" , event_csv_path = \"./user_data/events.csv\" , skip_duplicates = True , verbose = True , ): \"\"\" Ingest each level of experiment heirarchy for element-trial: recording, block (i.e., phases of trials), trials (repeated units), events (optionally 0-duration occurances within trial). This ingestion function is duplicated across wf-array-ephys and wf-calcium-imaging \"\"\" csvs = [ recording_csv_path , recording_csv_path , block_csv_path , block_csv_path , trial_csv_path , trial_csv_path , trial_csv_path , trial_csv_path , event_csv_path , event_csv_path , event_csv_path , ] tables = [ event . BehaviorRecording (), event . BehaviorRecording . File (), trial . Block (), trial . Block . Attribute (), trial . TrialType (), trial . Trial (), trial . Trial . Attribute (), trial . BlockTrial (), event . EventType (), event . Event (), trial . TrialEvent (), ] ingest_csv_to_table ( csvs , tables , skip_duplicates = skip_duplicates , verbose = verbose , allow_direct_insert = True , )", "title": "ingest_events()"}, {"location": "api/workflow_miniscope/ingest/#workflow_miniscope.ingest.ingest_subjects", "text": "Ingest subjects listed in the subject column of ./user_data/subjects.csv Source code in workflow_miniscope/ingest.py 11 12 13 14 15 16 17 18 19 20 def ingest_subjects ( subject_csv_path = \"./user_data/subjects.csv\" , skip_duplicates = True , verbose = True ): \"\"\" Ingest subjects listed in the subject column of ./user_data/subjects.csv \"\"\" csvs = [ subject_csv_path ] tables = [ subject . Subject ()] ingest_csv_to_table ( csvs , tables , skip_duplicates = skip_duplicates , verbose = verbose )", "title": "ingest_subjects()"}, {"location": "api/workflow_miniscope/ingest/#workflow_miniscope.ingest.recursive_search", "text": "Search through a nested dictionary for a key and returns its value. If there are more than one key with the same name at different depths, the algorithm returns the value of the least nested key. recursive_search(key, dictionary) :param key: key used to search through a nested dictionary :param dictionary: nested dictionary :return a: value of the input argument key Source code in workflow_miniscope/ingest.py 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def recursive_search ( key , dictionary ): \"\"\" Search through a nested dictionary for a key and returns its value. If there are more than one key with the same name at different depths, the algorithm returns the value of the least nested key. recursive_search(key, dictionary) :param key: key used to search through a nested dictionary :param dictionary: nested dictionary :return a: value of the input argument `key` \"\"\" if key in dictionary : return dictionary [ key ] for value in dictionary . values (): if isinstance ( value , dict ): a = recursive_search ( key , value ) if a is not None : return a return None", "title": "recursive_search()"}, {"location": "api/workflow_miniscope/paths/", "text": "", "title": "paths.py"}, {"location": "api/workflow_miniscope/pipeline/", "text": "", "title": "pipeline.py"}, {"location": "api/workflow_miniscope/populate/", "text": "", "title": "populate.py"}, {"location": "api/workflow_miniscope/version/", "text": "Package metadata", "title": "version.py"}]}